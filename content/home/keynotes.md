+++
# A Demo section created with the Blank widget.
# Any elements can be added in the body: https://sourcethemes.com/academic/docs/writing-markdown-latex/
# Add more sections by duplicating this file and customizing to your requirements.

widget = "blank"  # See https://sourcethemes.com/academic/docs/page-builder/
headless = true  # This file represents a page section.
active = true  # Activate this widget? true/false
weight = 455  # Order that this section will appear.

title = "Speakers"
subtitle = ""

[design]
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns = "2"
+++

## Large Scale Data Intensive Workflow Management 

Many large-scale scientific experiments take advantage of scientific workflows
to model data operations such as loading input data, data processing, data analysis,
and aggregating output data. Scientific workflows allow for scientists to easily model
and express the entire data processing steps and their dependencies, typically as a
Directed Acyclic Graph (i.e., DAG). As more and more data is consumed and produced in modern scientific experiments, scientific workflows become data-intensive, i.e., each execution of a workflow can generate many Gigabytes (or even Terabytes) of data. To process large-scale data within a reasonable time, workflows need to be executed with parallel processing techniques in distributed environments such as clouds environments. This talk aims at presenting a broad view of data-intensive workflow management systems in these different environments applied to different applications domains such as plant phenotyping and bioinformatics. Afterwards, I will present data management techniques (caching, scheduling) that enables to execute these workflows efficiently. 

**Esther Pacitti** is a full professor of computer science at University of Montpellier in the south of France. She is co-head of the Zenith team (Inria&Cnrs-Lirmm), pursuing her research in distributed data management and scientific data management. Her research interests include data replication, recommendation systems, query processing in large-scale distributed systems (cluster, P2P, cloud) and data intensive scientific workflow management. She has been involved in several national and international research projects. In particular, she has been actively collaborating with brazilian teams.  She has published more than 110 technical papers. She has served or is serving as program committee member of major international conferences including SIGMOD, ICDE, CIKM, VLDB, EDBT, etc.

 ## Real-time detection & nucleation of small earthquakes in Stable South America
 
 Monitoring earthquakes is the most basic task in seismology. The Brazilian Seismographic Network is a continental-wide network with more than 90 stations that are used to monitor Brazilian seismicity. While the network is a revolution in terms of available data most of the events in Brazil continue to be declared by visually analyzing day-plots records. We lack well-defined parameters and even, adapted procedures to search for events recorded by the network or a subset of it. The traditional process of declaring a new earthquake involves the detection of seismic phases arrival times, mainly P- and S-wave on continuous records, that later must be sorted and finally grouped to nucleate possible events while false detections must be discarded. The most simple and used detection algorithm is the STA/LTA method that returns detection times from continuous records.  The nucleation is a delicate process that normally works well on the global scale, or just when detection times of different events and phases are not mixed in time. Since earthquake position and origin time are not known, it is impossible to compute theoretical travel times at this stage. The information available is restricted to station coordinates and detection times. In some cases, instead of using detection time, the full detection waveform can be used. In that case, events must be nucleated directly from waveforms instead of considering the individual detection times.
 
**Marcelo Bianchi** is currently a professor at the Instituto de Astronomia, Geofísica e Ciências Atmosféricas from Universidade de São Paulo, where he develops research in the area of seismology, basically with the development of methods and procedures for detecting seismic events and studies of crust and mantle structure. He was also during the years of 2009-2010 a research scientist working for Schlumberger Stavanger Research Center in Norway and later a researcher inside the GEOFON group in Potsdam/Germany. He has experience with different programming languages, developing from small processing scripts to intermediate size, complex object-oriented programs to manage and process seismological data. 

 
 ## Scalable Machine Learning
 
 This course will provide students with an introduction to scalable Machine Learning. I will describe recent work on scalable clustering. By this course, I would like to teach students that the construction of scalable models is not necessarily associated with strictly computer engineering. The traditional steps of modeling and estimation remain essential. The course will be followed by a short Lab session using spark-notebook.io.
 
**Mustapha Lebbah** is currently Associate Professor at the University of Paris 13 and a member of Machine learning Team A3, LIPN. His main researches are centered on machine learning and data mining (Unsupervised Learning, Self-organizing map, Probabilistic and Statistic, scalable machine learning and data science). Graduated from USTO University where he received his engineer diploma in 1998. Thereafter, he gained an MSC (DEA) in Artificial Intelligence from the Paris 13 University in 1999. In 2003, after three year in RENAULT R&D, he received his PhD degree in Computer Science from the University of Versailles. He received the "Habilitation à Diriger des Recherches" (accreditation to lead research) degree in Computer Science from Paris 13 University in 2012. He is a member of the french group in "complex data mining", and Secretary for the French Classification Society since november 2012.
 
 ## Automation of  Machine Learning

 The use of computers to solve complex problems has made significant progress in recent years and an ever-growing number of disciplines rely on it. However, this progress weighty depends on human experts to perform manual tasks  such as hyperparameter optimization, neural architecture search, and dynamic algorithm configuration. As the complexity of these tasks is often beyond non-experts, a demand for off-the-shelf methods that can be used easily and without expert knowledge has emerged. This  research area that targets progressive automation of methods is called Automation  machine learning. Among those algorithms, deep learning, particularly deep convolutional neural networks have shown very good success and attracted attention from industry people and researchers in computer vision and image processing, neural networks, and machine learning. Our approach relies on evolutionary computation techniques (ES). ES started playing a significant role in automatically determining deep structures, transfer functions, and parameters to tackle image classification tasks, and have great potential to advance the developments of deep structures and algorithms. This talk will provide an extended view of deep learning, overview the state-of-the-art evolutionary deep learning using Genetic Programming (GP) to automatically evolving deep structures. Applications will be described on Image classification, image segmentation, and natural language processing.

**Aurora Pozo**  is currently a Professor of Computer Science at Universidade Federal do Paraná, where she heads the interdisciplinary Evolutionary Computation Research Group. Her scientific contributions are in the area of ​​computational intelligence, mainly focused on machine learning, and particularly in evolutionary computation and learning (using genetic programming, particle swarm optimization, and learning classifier systems), big dimensionality reduction, computer vision, and image processing, multi-objective optimization,  and evolutionary deep learning. In addition to technical contributions in the area of ​​computational intelligence, Aurora works to consolidate the area in Brazil, actively participating in events related to the area (BRACIS, ENIAC, CTDIAC). Having already organized the events and coordinated the BRACIS program committee. The bidder has coordinated CNPq Universal and Fundação Araucária projects in the area of ​​bioinspired computing and applications. The projects have the collaboration of professors from different Universities in the State of Paraná, such as the State University of Ponta Grossa and the State University of the Center-West. Internationally, she coordinated a project MCT/CAPES/CNPq PVE 400125/2014-5 which allowed fruitful cooperation with the University of the Vasco Country/Spain. She has participated as a scientific editor in special issues in the journal Natural Computing (2018), Neurocomputing (2015), in the Journal of the Brazilian Computer Society (JBCS 2015). She has also participated as a reviewer for different international scientific journals such as IEEE Transaction on Evolutionary Computation, Applied Soft Computing, Neurocomputing, Swarm and Evolutionary Computation and Information Sciences. Member of international conference program committees such as “Conference on Hybrid Intelligent System” and “Conference on Evolutionary Multi-criterion Optimization”. And nationally, she was co-chair of the Theses and Dissertations Contest in Artificial and Computational Intelligence (2018-2020). As well as a member of the CSBC Thesis and Dissertations Contest committees (2013, 2014, 2015, 2016, 2017 and 2018), among others. In addition to these activities, during this period, she has been dedicated to the training of human resources, continuously training masters and doctors. As well, it has published several articles in periodicals and conferences of recognized quality.

